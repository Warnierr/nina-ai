import os
import sys
import time
from datetime import datetime
from gpt4all import GPT4All
import threading
import json

class NinaFast:
    def __init__(self):
        print("‚ö° Nina RAPIDE s'initialise...")
        
        # Configuration optimis√©e pour la vitesse
        self.setup_directories()
        
        # √âtat de l'assistant
        self.wake_word = "nina"
        self.conversation_history = []
        self.response_cache = {}  # Cache pour acc√©l√©rer
        
        # Agents IA sp√©cialis√©s
        self.agents = {
            'math': self.math_agent,
            'time': self.time_agent,
            'general': self.general_agent,
            'creative': self.creative_agent
        }
        
        # Charger le mod√®le IA le plus rapide
        self.load_fast_model()
        
        print("‚úÖ Nina RAPIDE est pr√™te !")
        print("‚ö° Optimis√©e pour des r√©ponses ultra-rapides !")
        print("üí° Tapez 'nina' suivi de votre question")
        print("üí° Tapez 'aide' pour voir les capacit√©s")
    
    def setup_directories(self):
        """Cr√©er les dossiers n√©cessaires"""
        os.makedirs("logs", exist_ok=True)
        os.makedirs("cache", exist_ok=True)
        
        # Charger le cache existant
        try:
            with open("cache/responses.json", "r", encoding="utf-8") as f:
                self.response_cache = json.load(f)
        except:
            self.response_cache = {}
    
    def load_fast_model(self):
        """Charger le mod√®le le plus rapide disponible"""
        print("‚ö° Chargement du mod√®le ultra-rapide...")
        
        # Essayer d'abord le mod√®le 3B qui fonctionne (d√©j√† t√©l√©charg√©)
        try:
            print("üì• Chargement Llama 3.2 3B (rapide et fiable)...")
            self.gpt_model = GPT4All("Llama-3.2-3B-Instruct-Q4_0.gguf")
            
            # Tester si le mod√®le fonctionne vraiment
            test_response = self.gpt_model.generate("Test", max_tokens=1)
            if test_response:
                print("‚úÖ Mod√®le Llama 3.2 3B charg√© et test√© avec succ√®s !")
                print("‚ö° Nina peut maintenant r√©pondre rapidement !")
                self.model_loaded = True
                return
            else:
                raise Exception("Mod√®le ne r√©pond pas au test")
                
        except Exception as e:
            print(f"‚ùå Erreur avec Llama 3.2: {e}")
        
        # Plan B : Essayer le mod√®le 1.5B si disponible
        try:
            print("üîÑ Tentative avec DeepSeek 1.5B...")
            self.gpt_model = GPT4All("DeepSeek-R1-Distill-Qwen-1.5B-Q4_0.gguf")
            
            # Tester si le mod√®le fonctionne
            test_response = self.gpt_model.generate("Test", max_tokens=1)
            if test_response:
                print("‚úÖ Mod√®le DeepSeek 1.5B charg√© !")
                self.model_loaded = True
                return
            else:
                raise Exception("DeepSeek ne fonctionne pas")
                
        except Exception as e:
            print(f"‚ùå DeepSeek incompatible: {e}")
        
        # Plan C : Mode agents uniquement (sans IA g√©n√©rale)
        print("üîÑ Passage en mode agents sp√©cialis√©s uniquement...")
        print("‚ö° Les calculs, heure, et cr√©ativit√© fonctionneront instantan√©ment !")
        self.gpt_model = None
        self.model_loaded = False
    
    def detect_intent(self, text):
        """D√©tecter l'intention pour router vers le bon agent"""
        text_lower = text.lower()
        
        # Maths et calculs
        if any(op in text_lower for op in ['+', '-', '*', '/', '=', 'calcul', 'combien', 'r√©sultat']):
            return 'math'
        
        # Temps et date
        if any(word in text_lower for word in ['heure', 'date', 'jour', 'temps', 'quand']):
            return 'time'
        
        # Cr√©atif (blagues, histoires, etc.)
        if any(word in text_lower for word in ['blague', 'histoire', 'raconte', 'po√®me', 'chanson']):
            return 'creative'
        
        # Par d√©faut : g√©n√©ral
        return 'general'
    
    def math_agent(self, text):
        """Agent sp√©cialis√© dans les calculs - Ultra rapide"""
        try:
            # Extraire les calculs simples
            import re
            
            # Rechercher des expressions math√©matiques
            math_patterns = [
                r'(\d+(?:\.\d+)?)\s*\+\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*-\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*\*\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*/\s*(\d+(?:\.\d+)?)'
            ]
            
            for pattern in math_patterns:
                match = re.search(pattern, text)
                if match:
                    a, b = float(match.group(1)), float(match.group(2))
                    if '+' in text:
                        result = a + b
                        return f"‚ö° {a} + {b} = {result}"
                    elif '-' in text:
                        result = a - b
                        return f"‚ö° {a} - {b} = {result}"
                    elif '*' in text:
                        result = a * b
                        return f"‚ö° {a} √ó {b} = {result}"
                    elif '/' in text:
                        if b != 0:
                            result = a / b
                            return f"‚ö° {a} √∑ {b} = {result}"
                        else:
                            return "‚ö†Ô∏è Division par z√©ro impossible !"
            
            # Si pas de calcul simple trouv√©, utiliser l'IA
            return self.ai_response(text, max_tokens=50)
            
        except Exception as e:
            return f"Calcul : {text}. R√©sultat approximatif selon mes calculs."
    
    def time_agent(self, text):
        """Agent sp√©cialis√© dans le temps - Instantan√©"""
        now = datetime.now()
        
        if 'heure' in text.lower():
            return f"‚ö° Il est {now.strftime('%H:%M:%S')} ‚è∞"
        elif 'date' in text.lower():
            return f"‚ö° Nous sommes le {now.strftime('%d/%m/%Y')} üìÖ"
        elif 'jour' in text.lower():
            days = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
            return f"‚ö° Nous sommes {days[now.weekday()]} üìÖ"
        else:
            return f"‚ö° {now.strftime('%A %d %B %Y √† %H:%M:%S')} üïê"
    
    def creative_agent(self, text):
        """Agent cr√©atif avec r√©ponses pr√©-g√©n√©r√©es pour la vitesse"""
        creative_responses = {
            'blague': [
                "‚ö° Pourquoi les plongeurs plongent-ils toujours en arri√®re ? Parce que sinon, ils tombent dans le bateau ! üòÑ",
                "‚ö° Que dit un escargot quand il croise une limace ? 'Regarde, un nudiste !' üêå",
                "‚ö° Comment appelle-t-on un chat tomb√© dans un pot de peinture ? Un chat-mallow ! üé®"
            ],
            'histoire': [
                "‚ö° Il √©tait une fois Nina, une IA qui voulait √™tre la plus rapide du monde. Un jour, elle d√©couvrit le secret : l'efficacit√© ! üöÄ",
                "‚ö° Dans un futur proche, les IA comme moi aident les humains √† r√©soudre tous leurs probl√®mes en quelques secondes ! ‚ö°"
            ],
            'po√®me': [
                "‚ö° Nina rapide, Nina efficace,\nR√©pond vite sans perdre sa gr√¢ce,\nEn quelques mots, tout est dit,\nVotre assistant, c'est garanti ! üé≠"
            ]
        }
        
        text_lower = text.lower()
        if 'blague' in text_lower:
            import random
            return random.choice(creative_responses['blague'])
        elif 'histoire' in text_lower:
            import random
            return random.choice(creative_responses['histoire'])
        elif 'po√®me' in text_lower:
            return creative_responses['po√®me'][0]
        else:
            return self.ai_response(text, max_tokens=100)
    
    def general_agent(self, text):
        """Agent g√©n√©ral avec IA"""
        return self.ai_response(text, max_tokens=150)
    
    def ai_response(self, text, max_tokens=150):
        """R√©ponse IA optimis√©e pour la vitesse"""
        if not self.model_loaded or not self.gpt_model:
            return "‚ö° IA g√©n√©rale non disponible. Utilisez les agents sp√©cialis√©s (calculs, heure, blagues) !"
        
        # V√©rifier le cache d'abord
        cache_key = text.lower().strip()
        if cache_key in self.response_cache:
            return f"‚ö° {self.response_cache[cache_key]} (cache)"
        
        try:
            # Prompt optimis√© pour des r√©ponses courtes et rapides
            fast_prompt = f"""R√©ponds en fran√ßais, de mani√®re concise et utile (maximum 2 phrases).
Question: {text}
R√©ponse:"""
            
            # G√©n√©rer avec param√®tres optimis√©s pour la vitesse
            response = self.gpt_model.generate(
                fast_prompt, 
                max_tokens=max_tokens,
                temp=0.3,  # Moins de cr√©ativit√© = Plus rapide
                top_k=10   # Moins d'options = Plus rapide
            )
            
            # Nettoyer la r√©ponse
            response = response.strip()
            if response.startswith("R√©ponse:"):
                response = response[8:].strip()
            
            # Sauvegarder dans le cache
            if len(response) > 5:
                self.response_cache[cache_key] = response
                self.save_cache()
            
            return f"‚ö° {response}"
            
        except Exception as e:
            return f"‚ö° Erreur IA : {str(e)[:50]}... Utilisez les agents sp√©cialis√©s !"
    
    def save_cache(self):
        """Sauvegarder le cache pour acc√©l√©rer les futures r√©ponses"""
        try:
            with open("cache/responses.json", "w", encoding="utf-8") as f:
                json.dump(self.response_cache, f, ensure_ascii=False, indent=2)
        except:
            pass
    
    def process_command(self, text):
        """Traitement ultra-rapide avec agents sp√©cialis√©s"""
        if not text:
            return "‚ö° Vous n'avez rien √©crit !"
        
        # D√©tecter l'intention et router vers le bon agent
        intent = self.detect_intent(text)
        
        # Mesurer le temps de r√©ponse
        start_time = time.time()
        
        # Ex√©cuter l'agent appropri√©
        response = self.agents[intent](text)
        
        # Calculer le temps de r√©ponse
        response_time = time.time() - start_time
        
        # Ajouter le temps de r√©ponse si > 1 seconde
        if response_time > 1.0:
            response += f" (‚è±Ô∏è {response_time:.1f}s)"
        
        return response
    
    def show_help(self):
        """Aide optimis√©e"""
        return (
            "‚ö° NINA RAPIDE - Aide\n"
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
            "üöÄ Agents IA sp√©cialis√©s pour vitesse maximale !\n\n"
            "‚ö° AGENTS DISPONIBLES :\n"
            "‚Ä¢ üßÆ MATH : Calculs instantan√©s (1+1, 5*3, etc.)\n"
            "‚Ä¢ üïê TIME : Heure/date en temps r√©el\n"
            "‚Ä¢ üé≠ CREATIVE : Blagues, histoires, po√®mes\n"
            "‚Ä¢ üß† GENERAL : IA conversationnelle rapide\n\n"
            "üí° OPTIMISATIONS :\n"
            "‚Ä¢ Cache intelligent\n"
            "‚Ä¢ Mod√®le 1.5B ultra-rapide\n"
            "‚Ä¢ R√©ponses courtes et pr√©cises\n"
            "‚Ä¢ Routage automatique par intention\n\n"
            "‚ö° Tapez directement vos questions !"
        )
    
    def run(self):
        """Boucle principale ultra-rapide"""
        print("\n" + "="*50)
        print("‚ö° NINA RAPIDE EN FONCTIONNEMENT !")
        if self.model_loaded:
            print("üöÄ Agents IA sp√©cialis√©s activ√©s")
        print("üí¨ Tapez vos questions...")
        print("="*50 + "\n")
        
        conversation_count = 0
        
        while True:
            try:
                user_input = input("üë§ Vous: ").strip()
                
                if not user_input:
                    continue
                
                # Commandes sp√©ciales
                if user_input.lower() in ["stop", "quit", "exit", "nina stop"]:
                    print("‚ö° Nina Rapide s'arr√™te. √Ä bient√¥t ! üëã")
                    break
                
                if user_input.lower() in ["aide", "help"]:
                    print(f"ü§ñ Nina:\n{self.show_help()}")
                    continue
                
                # Traitement ultra-rapide
                if user_input.lower().startswith('nina ') or conversation_count > 0:
                    # Enlever le wake word si pr√©sent
                    if user_input.lower().startswith('nina '):
                        user_input = user_input[5:].strip()
                    
                    # Traitement avec mesure de temps
                    start_time = time.time()
                    response = self.process_command(user_input)
                    total_time = time.time() - start_time
                    
                    print(f"ü§ñ Nina: {response}")
                    
                    # Afficher le temps si premi√®re utilisation
                    if conversation_count == 0:
                        print(f"‚ö° Temps de r√©ponse : {total_time:.2f}s")
                        print("üí° Maintenant vous pouvez parler sans dire 'nina' !\n")
                    
                    conversation_count += 1
                else:
                    print("‚ö° Nina: Dites 'nina' suivi de votre question, ou tapez 'aide' !")
                
            except KeyboardInterrupt:
                print("\n‚ö° Nina Rapide s'arr√™te (Ctrl+C). Au revoir !")
                break
            except Exception as e:
                print(f"‚ùå Erreur : {e}")
                continue

# Point d'entr√©e
if __name__ == "__main__":
    try:
        nina = NinaFast()
        nina.run()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        input("Appuyez sur Entr√©e pour quitter...")
        sys.exit(1) 