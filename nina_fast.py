import os
import sys
import time
from datetime import datetime
from gpt4all import GPT4All
import threading
import json

class NinaFast:
    def __init__(self):
        print("âš¡ Nina RAPIDE s'initialise...")
        
        # Configuration optimisÃ©e pour la vitesse
        self.setup_directories()
        
        # Ã‰tat de l'assistant
        self.wake_word = "nina"
        self.conversation_history = []
        self.response_cache = {}  # Cache pour accÃ©lÃ©rer
        
        # Agents IA spÃ©cialisÃ©s
        self.agents = {
            'math': self.math_agent,
            'time': self.time_agent,
            'general': self.general_agent,
            'creative': self.creative_agent
        }
        
        # Charger le modÃ¨le IA le plus rapide
        self.load_fast_model()
        
        print("âœ… Nina RAPIDE est prÃªte !")
        print("âš¡ OptimisÃ©e pour des rÃ©ponses ultra-rapides !")
        print("ğŸ’¡ Tapez 'nina' suivi de votre question")
        print("ğŸ’¡ Tapez 'aide' pour voir les capacitÃ©s")
    
    def setup_directories(self):
        """CrÃ©er les dossiers nÃ©cessaires"""
        os.makedirs("logs", exist_ok=True)
        os.makedirs("cache", exist_ok=True)
        
        # Charger le cache existant
        try:
            with open("cache/responses.json", "r", encoding="utf-8") as f:
                self.response_cache = json.load(f)
        except:
            self.response_cache = {}
    
    def load_fast_model(self):
        """Charger le modÃ¨le le plus rapide disponible"""
        print("âš¡ Chargement du modÃ¨le ultra-rapide...")
        
        # Essayer d'abord le modÃ¨le 3B qui fonctionne (dÃ©jÃ  tÃ©lÃ©chargÃ©)
        try:
            print("ğŸ“¥ Chargement Llama 3.2 3B (rapide et fiable)...")
            self.gpt_model = GPT4All("Llama-3.2-3B-Instruct-Q4_0.gguf")
            
            # Tester si le modÃ¨le fonctionne vraiment
            test_response = self.gpt_model.generate("Test", max_tokens=1)
            if test_response:
                print("âœ… ModÃ¨le Llama 3.2 3B chargÃ© et testÃ© avec succÃ¨s !")
                print("âš¡ Nina peut maintenant rÃ©pondre rapidement !")
                self.model_loaded = True
                return
            else:
                raise Exception("ModÃ¨le ne rÃ©pond pas au test")
                
        except Exception as e:
            print(f"âŒ Erreur avec Llama 3.2: {e}")
        
        # Plan B : Essayer le modÃ¨le 1.5B si disponible
        try:
            print("ğŸ”„ Tentative avec DeepSeek 1.5B...")
            self.gpt_model = GPT4All("DeepSeek-R1-Distill-Qwen-1.5B-Q4_0.gguf")
            
            # Tester si le modÃ¨le fonctionne
            test_response = self.gpt_model.generate("Test", max_tokens=1)
            if test_response:
                print("âœ… ModÃ¨le DeepSeek 1.5B chargÃ© !")
                self.model_loaded = True
                return
            else:
                raise Exception("DeepSeek ne fonctionne pas")
                
        except Exception as e:
            print(f"âŒ DeepSeek incompatible: {e}")
        
        # Plan C : Mode agents uniquement (sans IA gÃ©nÃ©rale)
        print("ğŸ”„ Passage en mode agents spÃ©cialisÃ©s uniquement...")
        print("âš¡ Les calculs, heure, et crÃ©ativitÃ© fonctionneront instantanÃ©ment !")
        self.gpt_model = None
        self.model_loaded = False
    
    def detect_intent(self, text):
        """DÃ©tecter l'intention pour router vers le bon agent"""
        text_lower = text.lower()
        
        # Maths et calculs
        if any(op in text_lower for op in ['+', '-', '*', '/', '=', 'calcul', 'combien', 'rÃ©sultat']):
            return 'math'
        
        # Temps et date
        if any(word in text_lower for word in ['heure', 'date', 'jour', 'temps', 'quand']):
            return 'time'
        
        # CrÃ©atif (blagues, histoires, etc.)
        if any(word in text_lower for word in ['blague', 'histoire', 'raconte', 'poÃ¨me', 'chanson']):
            return 'creative'
        
        # Par dÃ©faut : gÃ©nÃ©ral
        return 'general'
    
    def math_agent(self, text):
        """Agent spÃ©cialisÃ© dans les calculs - Ultra rapide"""
        try:
            # Extraire les calculs simples
            import re
            
            # Rechercher des expressions mathÃ©matiques
            math_patterns = [
                r'(\d+(?:\.\d+)?)\s*\+\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*-\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*\*\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*/\s*(\d+(?:\.\d+)?)'
            ]
            
            for pattern in math_patterns:
                match = re.search(pattern, text)
                if match:
                    a, b = float(match.group(1)), float(match.group(2))
                    if '+' in text:
                        result = a + b
                        return f"âš¡ {a} + {b} = {result}"
                    elif '-' in text:
                        result = a - b
                        return f"âš¡ {a} - {b} = {result}"
                    elif '*' in text:
                        result = a * b
                        return f"âš¡ {a} Ã— {b} = {result}"
                    elif '/' in text:
                        if b != 0:
                            result = a / b
                            return f"âš¡ {a} Ã· {b} = {result}"
                        else:
                            return "âš ï¸ Division par zÃ©ro impossible !"
            
            # Si pas de calcul simple trouvÃ©, utiliser l'IA
            return self.ai_response(text, max_tokens=50)
            
        except Exception as e:
            return f"Calcul : {text}. RÃ©sultat approximatif selon mes calculs."
    
    def time_agent(self, text):
        """Agent spÃ©cialisÃ© dans le temps - InstantanÃ©"""
        now = datetime.now()
        
        if 'heure' in text.lower():
            return f"âš¡ Il est {now.strftime('%H:%M:%S')} â°"
        elif 'date' in text.lower():
            return f"âš¡ Nous sommes le {now.strftime('%d/%m/%Y')} ğŸ“…"
        elif 'jour' in text.lower():
            days = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
            return f"âš¡ Nous sommes {days[now.weekday()]} ğŸ“…"
        else:
            return f"âš¡ {now.strftime('%A %d %B %Y Ã  %H:%M:%S')} ğŸ•"
    
    def creative_agent(self, text):
        """Agent crÃ©atif avec rÃ©ponses prÃ©-gÃ©nÃ©rÃ©es pour la vitesse"""
        creative_responses = {
            'blague': [
                "âš¡ Pourquoi les plongeurs plongent-ils toujours en arriÃ¨re ? Parce que sinon, ils tombent dans le bateau ! ğŸ˜„",
                "âš¡ Que dit un escargot quand il croise une limace ? 'Regarde, un nudiste !' ğŸŒ",
                "âš¡ Comment appelle-t-on un chat tombÃ© dans un pot de peinture ? Un chat-mallow ! ğŸ¨"
            ],
            'histoire': [
                "âš¡ Il Ã©tait une fois Nina, une IA qui voulait Ãªtre la plus rapide du monde. Un jour, elle dÃ©couvrit le secret : l'efficacitÃ© ! ğŸš€",
                "âš¡ Dans un futur proche, les IA comme moi aident les humains Ã  rÃ©soudre tous leurs problÃ¨mes en quelques secondes ! âš¡"
            ],
            'poÃ¨me': [
                "âš¡ Nina rapide, Nina efficace,\nRÃ©pond vite sans perdre sa grÃ¢ce,\nEn quelques mots, tout est dit,\nVotre assistant, c'est garanti ! ğŸ­"
            ]
        }
        
        text_lower = text.lower()
        if 'blague' in text_lower:
            import random
            return random.choice(creative_responses['blague'])
        elif 'histoire' in text_lower:
            import random
            return random.choice(creative_responses['histoire'])
        elif 'poÃ¨me' in text_lower:
            return creative_responses['poÃ¨me'][0]
        else:
            return self.ai_response(text, max_tokens=100)
    
    def general_agent(self, text):
        """Agent gÃ©nÃ©ral avec IA"""
        return self.ai_response(text, max_tokens=150)
    
    def ai_response(self, text, max_tokens=150):
        """RÃ©ponse IA optimisÃ©e pour la vitesse"""
        if not self.model_loaded or not self.gpt_model:
            return "âš¡ IA gÃ©nÃ©rale non disponible. Utilisez les agents spÃ©cialisÃ©s (calculs, heure, blagues) !"
        
        # VÃ©rifier le cache d'abord
        cache_key = text.lower().strip()
        if cache_key in self.response_cache:
            return f"âš¡ {self.response_cache[cache_key]} (cache)"
        
        try:
            # Prompt optimisÃ© pour des rÃ©ponses courtes et rapides
            fast_prompt = f"""RÃ©ponds en franÃ§ais, de maniÃ¨re concise et utile (maximum 2 phrases).
Question: {text}
RÃ©ponse:"""
            
            # GÃ©nÃ©rer avec paramÃ¨tres optimisÃ©s pour la vitesse
            response = self.gpt_model.generate(
                fast_prompt, 
                max_tokens=max_tokens,
                temp=0.3,  # Moins de crÃ©ativitÃ© = Plus rapide
                top_k=10   # Moins d'options = Plus rapide
            )
            
            # Nettoyer la rÃ©ponse
            response = response.strip()
            if response.startswith("RÃ©ponse:"):
                response = response[8:].strip()
            
            # Sauvegarder dans le cache
            if len(response) > 5:
                self.response_cache[cache_key] = response
                self.save_cache()
            
            return f"âš¡ {response}"
            
        except Exception as e:
            return f"âš¡ Erreur IA : {str(e)[:50]}... Utilisez les agents spÃ©cialisÃ©s !"
    
    def save_cache(self):
        """Sauvegarder le cache pour accÃ©lÃ©rer les futures rÃ©ponses"""
        try:
            with open("cache/responses.json", "w", encoding="utf-8") as f:
                json.dump(self.response_cache, f, ensure_ascii=False, indent=2)
        except:
            pass
    
    def process_command(self, text):
        """Traitement ultra-rapide avec agents spÃ©cialisÃ©s"""
        if not text:
            return "âš¡ Vous n'avez rien Ã©crit !"
        
        # DÃ©tecter l'intention et router vers le bon agent
        intent = self.detect_intent(text)
        
        # Mesurer le temps de rÃ©ponse
        start_time = time.time()
        
        # ExÃ©cuter l'agent appropriÃ©
        response = self.agents[intent](text)
        
        # Calculer le temps de rÃ©ponse
        response_time = time.time() - start_time
        
        # Ajouter le temps de rÃ©ponse si > 1 seconde
        if response_time > 1.0:
            response += f" (â±ï¸ {response_time:.1f}s)"
        
        return response
    
    def show_help(self):
        """Aide optimisÃ©e"""
        return (
            "âš¡ NINA RAPIDE - Aide\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "ğŸš€ Agents IA spÃ©cialisÃ©s pour vitesse maximale !\n\n"
            "âš¡ AGENTS DISPONIBLES :\n"
            "â€¢ ğŸ§® MATH : Calculs instantanÃ©s (1+1, 5*3, etc.)\n"
            "â€¢ ğŸ• TIME : Heure/date en temps rÃ©el\n"
            "â€¢ ğŸ­ CREATIVE : Blagues, histoires, poÃ¨mes\n"
            "â€¢ ğŸ§  GENERAL : IA conversationnelle rapide\n\n"
            "ğŸ’¡ OPTIMISATIONS :\n"
            "â€¢ Cache intelligent\n"
            "â€¢ ModÃ¨le 1.5B ultra-rapide\n"
            "â€¢ RÃ©ponses courtes et prÃ©cises\n"
            "â€¢ Routage automatique par intention\n\n"
            "âš¡ Tapez directement vos questions !"
        )
    
    def run(self):
        """Boucle principale ultra-rapide"""
        print("\n" + "="*50)
        print("âš¡ NINA RAPIDE EN FONCTIONNEMENT !")
        if self.model_loaded:
            print("ğŸš€ Agents IA spÃ©cialisÃ©s activÃ©s")
        print("ğŸ’¬ Tapez vos questions...")
        print("="*50 + "\n")
        
        conversation_count = 0
        
        while True:
            try:
                user_input = input("ğŸ‘¤ Vous: ").strip()
                
                if not user_input:
                    continue
                
                # Commandes spÃ©ciales
                if user_input.lower() in ["stop", "quit", "exit", "nina stop"]:
                    print("âš¡ Nina Rapide s'arrÃªte. Ã€ bientÃ´t ! ğŸ‘‹")
                    break
                
                if user_input.lower() in ["aide", "help"]:
                    print(f"ğŸ¤– Nina:\n{self.show_help()}")
                    continue
                
                # Traitement ultra-rapide
                if user_input.lower().startswith('nina ') or conversation_count > 0:
                    # Enlever le wake word si prÃ©sent
                    if user_input.lower().startswith('nina '):
                        user_input = user_input[5:].strip()
                    
                    # Traitement avec mesure de temps
                    start_time = time.time()
                    response = self.process_command(user_input)
                    total_time = time.time() - start_time
                    
                    print(f"ğŸ¤– Nina: {response}")
                    
                    # Afficher le temps si premiÃ¨re utilisation
                    if conversation_count == 0:
                        print(f"âš¡ Temps de rÃ©ponse : {total_time:.2f}s")
                        print("ğŸ’¡ Maintenant vous pouvez parler sans dire 'nina' !\n")
                    
                    conversation_count += 1
                else:
                    print("âš¡ Nina: Dites 'nina' suivi de votre question, ou tapez 'aide' !")
                
            except KeyboardInterrupt:
                print("\nâš¡ Nina Rapide s'arrÃªte (Ctrl+C). Au revoir !")
                break
            except Exception as e:
                print(f"âŒ Erreur : {e}")
                continue

# Point d'entrÃ©e
if __name__ == "__main__":
    try:
        nina = NinaFast()
        nina.run()
    except Exception as e:
        print(f"âŒ Erreur fatale: {e}")
        input("Appuyez sur EntrÃ©e pour quitter...")
        sys.exit(1) 